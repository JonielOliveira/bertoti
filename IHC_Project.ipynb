{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonielOliveira/bertoti/blob/interacao-humano-computador/IHC_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2ppDodw9_5Y"
      },
      "source": [
        "# **[1] – IMPLEMENTAÇÃO:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt2U_AAQhX7r"
      },
      "source": [
        "## [1.1] – GOOGLE DRIVE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAohjQahNX-o"
      },
      "source": [
        "### [1.1.1] – *GOOGLE DRIVE » CRIAR A CONEXÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjXmRva3tkw8"
      },
      "source": [
        "Este código monta o Google Drive no ambiente do Google Colab, permitindo acessar e manipular arquivos armazenados no Drive diretamente do Colab. Cria os diretórios necessários, caso não existam."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Caminhos dos diretórios principais\n",
        "base_dir = \"/content/drive/MyDrive/IHC\"\n",
        "data_dir = os.path.join(base_dir, \"data\")\n",
        "log_dir = os.path.join(base_dir, \"log\")\n",
        "credentials_dir = os.path.join(base_dir, \"credentials\")\n",
        "\n",
        "# Subdiretórios dentro de \"data\"\n",
        "data_subdirs = [\n",
        "    \"P1-input-audio\",\n",
        "    \"P2-input-txt\",\n",
        "    \"P3-llm-response\",\n",
        "    \"P4-api-response\",\n",
        "    \"P5-noticia\",\n",
        "    \"P5-output-txt\",\n",
        "    \"P6-output-audio\"\n",
        "]\n",
        "\n",
        "# Função para criar diretórios se não existirem\n",
        "def criar_diretorios(diretorios):\n",
        "    for diretorio in diretorios:\n",
        "        os.makedirs(diretorio, exist_ok=True)\n",
        "        print(f\"Diretório criado ou já existente: {diretorio}\")\n",
        "\n",
        "# Criar os diretórios principais\n",
        "criar_diretorios([base_dir, data_dir, log_dir, credentials_dir])\n",
        "\n",
        "# Criar os subdiretórios dentro de \"data\"\n",
        "criar_diretorios([os.path.join(data_dir, subdir) for subdir in data_subdirs])\n"
      ],
      "metadata": {
        "id": "XhIs5SGlcEPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQleyvjJNz5s"
      },
      "source": [
        "### [1.1.2] – *GOOGLE DRIVE » LER AS CHAVES DA APLICAÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ftkT9I7uf36"
      },
      "source": [
        "Este código carrega um arquivo JSON contendo chaves de aplicação do Google Drive a partir do diretório montado no Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zC-2EqGFE4Q_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Caminho do arquivo JSON\n",
        "arquivo_credencial = '/content/drive/MyDrive/IHC/credentials/credential_gcloud.json'\n",
        "\n",
        "# Definir as credenciais em uma variável de ambiente\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = arquivo_credencial\n",
        "\n",
        "# Abrindo o arquivo JSON para leitura\n",
        "# with open(arquivo_chaves, 'r') as arquivo:\n",
        "#    chaves = json.load(arquivo)\n",
        "\n",
        "# Função para obter a chave associada ao nome\n",
        "# def obter_chave(chaves, nome):\n",
        "#  for chave in chaves:\n",
        "#    if chave['name'] == nome:\n",
        "#      return chave['key']\n",
        "#  return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0PQlixAebu1"
      },
      "source": [
        "## [1.2] – OPENAI WHISPER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLaa4m9a8eU"
      },
      "source": [
        "### [1.2.1] – *OPENAI WHISPER » INSTALAÇÃO DAS DEPENDÊNCIAS:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0xjS_o3w2eN"
      },
      "source": [
        "Este código instala as dependências necessárias para usar o modelo OpenAI Whisper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mtxDo8MUNLIR"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install ffmpeg\n",
        "!pip install torch numpy\n",
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RwhexSPaaj9"
      },
      "source": [
        "### [1.2.2] – *OPENAI WHISPER » IMPLEMENTAÇÃO DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3NitoWFxLD8"
      },
      "source": [
        "Este código define uma função que usa o modelo OpenAI Whisper para transcrever áudio em texto. A função carrega o modelo, transcreve o áudio em português e salva o texto resultante em um arquivo de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2pJepMYMlUx"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import whisper\n",
        "\n",
        "# Ignora warnings específicos\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "def audio_para_texto(input_file, output_file):\n",
        "\n",
        "  # Carrega o modelo Whisper\n",
        "  model = whisper.load_model(\"base\")\n",
        "\n",
        "  # Transcreve o áudio, especificando o idioma como português\n",
        "  result = model.transcribe(input_file, language=\"pt\")\n",
        "\n",
        "  # Salva o texto transcrito em um arquivo\n",
        "  with open(output_file, \"w\") as f:\n",
        "    f.write(result[\"text\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_05IcrG81yG"
      },
      "source": [
        "## [1.4] – LARGE LANGUAGE MODEL (LLM):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4CMmZefXPx1"
      },
      "source": [
        "### [1.4.1] – *LARGE LANGUAGE MODEL(LLM) » IMPLEMENTAÇÃO DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk3OsaeugUYI"
      },
      "source": [
        "Configura um modelo de linguagem (LLM) para gerar respostas a perguntas com base em exemplos fornecidos. Cria um pipeline de geração de texto usando o modelo Phi-3-mini-4k-instruct e define uma função que recebe uma pergunta, gera uma resposta identificando os tópicos de interesse, e retorna essa resposta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_OaFhTCHNjj"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "# Define o modelo a ser utilizado\n",
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "# Cria o pipeline de geração de texto\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Função para gerar a resposta\n",
        "def gerar_resposta(pergunta):\n",
        "\n",
        "    # Orienta o LLM para que responda de uma forma previsível\n",
        "    pergunta_exemplo_1 = \"Bom dia, gostaria de saber como está o PIB.\"\n",
        "    resposta_exemplo_1 = \"PIB\"\n",
        "    pergunta_exemplo_2 = \"Olá, poderia me informar sobre a agropecuária?\"\n",
        "    resposta_exemplo_2 = \"agropecuária\"\n",
        "    pergunta_exemplo_3 = \"Boa tarde, como está o IPCA ou INPC atualmente?\"\n",
        "    resposta_exemplo_3 = \"IPCA, INPC\"\n",
        "\n",
        "    prompt = (f\"Identifique quais os tópicos de interesse do usuário ao realizar uma pergunta e liste-os.\\n\\n\"\n",
        "              f\"Você recebeu as seguintes perguntas e respostas como exemplos:\\n\\n\"\n",
        "              f\"Pergunta exemplo 1: {pergunta_exemplo_1}\\n\"\n",
        "              f\"Resposta exemplo 1: {resposta_exemplo_1}\\n\\n\"\n",
        "              f\"Pergunta exemplo 2: {pergunta_exemplo_2}\\n\"\n",
        "              f\"Resposta exemplo 2: {resposta_exemplo_2}\\n\\n\"\n",
        "              f\"Pergunta exemplo 3: {pergunta_exemplo_3}\\n\"\n",
        "              f\"Resposta exemplo 3: {resposta_exemplo_3}\\n\\n\"\n",
        "              f\"Agora, responda a nova pergunta com base no estilo da resposta exemplo.\\n\\n\"\n",
        "              f\"Nova Pergunta: {pergunta}\\n\"\n",
        "              f\"Resposta:\")\n",
        "\n",
        "    resposta = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=50,                  # Limita o número de tokens gerados\n",
        "        do_sample=False,                    # Gera uma resposta determinística\n",
        "        num_return_sequences=1,             # Retorna apenas uma sequência\n",
        "        eos_token_id=50256,                 # Configura o token de fim de sequência (ajuda o modelo a saber quando parar)\n",
        "        clean_up_tokenization_spaces=True,  # Remove espaços desnecessários\n",
        "        stop_sequence=\"###\"                 # Impede a repetição de prompt ou metadados\n",
        "    )\n",
        "\n",
        "    # Filtra a resposta apenas até o fim da primeira frase gerada\n",
        "\n",
        "    # Obtém o texto gerado\n",
        "    texto_gerado = resposta[0]['generated_text']\n",
        "\n",
        "    # Encontrar o índice de \"Resposta:\"\n",
        "    inicio_resposta = texto_gerado.find(\"Resposta:\") + len(\"Resposta:\")\n",
        "\n",
        "    # Encontrar o índice de \"\\n\\n\" após \"Resposta:\"\n",
        "    fim_resposta = texto_gerado.find(\"\\n\\n\", inicio_resposta)\n",
        "\n",
        "    # Extrair o intervalo entre \"Resposta:\" e \"\\n\\n\"\n",
        "    if inicio_resposta != -1 and fim_resposta != -1:\n",
        "        return texto_gerado[inicio_resposta:fim_resposta].strip()\n",
        "    else:\n",
        "        # Se não encontrar os delimitadores, retorna uma mensagem padrão ou ajusta conforme necessário\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMNUK6zIf6oU"
      },
      "source": [
        "## [1.5] – API IBGE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca4xGTe0gOKQ"
      },
      "source": [
        "### [1.5.1] – *API IBGE » IMPLEMENTAÇÃO DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu7ca9i7gdTQ"
      },
      "source": [
        "Realiza consultas à API do IBGE (https://servicodados.ibge.gov.br/api/docs/noticias?versao=3) para buscar notícias relacionadas a um termo especificado. Define uma classe Noticia para armazenar e formatar as informações obtidas. A função realizar_consulta envia a consulta e a função obter_noticias extrai e retorna uma lista de notícias formatadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgbdyVmtf3Jj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "class Noticia:\n",
        "    def __init__(self, titulo, introducao, data_publicacao, link):\n",
        "        self.titulo = titulo\n",
        "        self.introducao = introducao\n",
        "        self.data_publicacao = data_publicacao\n",
        "        self.link = link\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"titulo\": self.titulo,\n",
        "            \"introducao\": self.introducao,\n",
        "            \"data_publicacao\": self.data_publicacao,\n",
        "            \"link\": self.link\n",
        "        }\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Titulo={self.titulo!r}\\nIntroducao={self.introducao!r}\\nData_Publicacao={self.data_publicacao!r}\\nLink={self.link!r}\"\n",
        "\n",
        "def realizar_consulta(solicitacao):\n",
        "    url_base = 'https://servicodados.ibge.gov.br/api/v3/noticias/?busca='\n",
        "    busca = quote(solicitacao)\n",
        "    url = url_base + busca\n",
        "    dados = requests.get(url).json()\n",
        "    return dados\n",
        "\n",
        "def obter_noticias(dados):\n",
        "    if dados.get('count'):\n",
        "        if dados['count'] > 0:\n",
        "            noticias = []\n",
        "            items = dados['items']\n",
        "            if (len(items) > 0):\n",
        "                for item in items:\n",
        "                    nova_noticia = Noticia(\n",
        "                        titulo=item.get('titulo'),\n",
        "                        introducao=item.get('introducao'),\n",
        "                        data_publicacao=item.get('data_publicacao'),\n",
        "                        link=item.get('link')\n",
        "                        )\n",
        "                    noticias.append(nova_noticia)\n",
        "                return noticias\n",
        "            else:\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlJrsR89_jb6"
      },
      "source": [
        "## [1.6] – BOT TELEGRAM:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-qdgtGS7-FC"
      },
      "source": [
        "### [1.6.1] – *BOT TELEGRAM » INSTALAÇÃO DAS DEPENDÊNCIAS:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOwU4lLFgt_o"
      },
      "source": [
        " Instala bibliotecas necessárias para a criação de um bot no Telegram (python-telegram-bot), manipulação de modelos de linguagem (llama_cpp_python), e interação com a API do Telegram (pytelegrambotapi)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9sWGWwgcSaXq"
      },
      "outputs": [],
      "source": [
        "!pip install python-telegram-bot==13.7\n",
        "!pip install llama_cpp_python\n",
        "!pip install pytelegrambotapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGYPhykG8tEk"
      },
      "source": [
        "### [1.6.2] – *BOT TELEGRAM » IMPLEMENTAÇÃO DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Y4hdC8g3uu"
      },
      "source": [
        "Configura um bot do Telegram para receber mensagens de voz. O áudio é transcrito e interpretado para identificar tópicos de interesse. Com base nos tópicos, consulta a API do IBGE, gera um resumo das notícias relacionadas, converte o resumo em áudio, e envia esse áudio de volta ao usuário, junto com informações adicionais, como data e link da notícia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5lJZPJGXlsA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "\n",
        "def encontrar_substring_em_listas(lista_strings_a, lista_strings_b):\n",
        "    # Converte todas as strings em lista_strings_b para minúsculas\n",
        "    lista_strings_b_lower = [s.lower() for s in lista_strings_b]\n",
        "\n",
        "    # Itera sobre cada string em lista_strings_a\n",
        "    for s_a in lista_strings_a:\n",
        "        # Converte a string de lista_strings_a para minúsculas\n",
        "        s_a_lower = s_a.lower()\n",
        "\n",
        "        # Verifica se a string de lista_strings_a está contida em alguma das strings de lista_strings_b\n",
        "        if any(s_a_lower in s_b_lower for s_b_lower in lista_strings_b_lower):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def agora_file():\n",
        "  # Obtém a data e hora atual\n",
        "  agora = datetime.now()\n",
        "\n",
        "  # Formata a data e hora no formato desejado\n",
        "  data_e_hora_formatada = agora.strftime(\"_%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "  # Retorna a data e hora formatada\n",
        "  return data_e_hora_formatada\n",
        "\n",
        "def agora_log():\n",
        "  # Obtém a data e hora atual\n",
        "  agora = datetime.now()\n",
        "\n",
        "  # Formata a data e hora no formato desejado\n",
        "  data_e_hora_formatada = agora.strftime(\"[%d/%m/%Y %H:%M:%S]\")\n",
        "\n",
        "  # Retorna a data e hora formatada\n",
        "  return data_e_hora_formatada\n",
        "\n",
        "def hoje_log():\n",
        "    # Obtém a data atual\n",
        "    agora = datetime.now()\n",
        "\n",
        "    # Formata a data no formato \"ano-mes-dia\"\n",
        "    data_formatada = agora.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Retorna a data formatada\n",
        "    return data_formatada\n",
        "\n",
        "def create_log(indicador, file_location):\n",
        "  status = [\"Status 1: áudio de entrada recebido com sucesso! \\n»»» (FILE)\",\n",
        "            \"Status 2: transcrição da entrada gerada com sucesso! \\n»»» (FILE)\",\n",
        "            \"Status 3: resposta do LLM gerada com sucesso! \\n»»» (FILE)\",\n",
        "            \"Status 4: resposta do API IBGE obtida com sucesso! \\n»»» (FILE)\",\n",
        "            \"Status 5: notícia salva com sucesso! \\n»»» (FILE)\",\n",
        "            \"Status 6: áudio de saida gerado com sucesso! \\n»»» (FILE)\"]\n",
        "  resposta = f\"{agora_log()} {status[indicador - 1].replace(\"FILE\", file_location)}\"\n",
        "\n",
        "\n",
        "import telebot\n",
        "\n",
        "# Substitua 'TELEGRAM_API_KEY' pela sua chave de API do Telegram Bot\n",
        "bot = telebot.TeleBot(userdata.get('TELEGRAM_API_KEY'))\n",
        "\n",
        "@bot.message_handler(content_types=['voice'])\n",
        "def handle_voice_message(message):\n",
        "\n",
        "    locations = {\n",
        "        \"audio_entrada\": \"/content/drive/MyDrive/IHC/data/P1-input-audio/\",\n",
        "        \"transcricao_entrada\": \"/content/drive/MyDrive/IHC/data/P2-input-txt/\",\n",
        "        \"llm_response\": \"/content/drive/MyDrive/IHC/data/P3-llm-response/\",\n",
        "        \"api_response\": \"/content/drive/MyDrive/IHC/data/P4-api-response/\",\n",
        "        \"noticia\": \"/content/drive/MyDrive/IHC/data/P5-noticia/\",\n",
        "        \"transcricao_saida\": \"/content/drive/MyDrive/IHC/data/P5-output-txt/\",\n",
        "        \"audio_saida\": \"/content/drive/MyDrive/IHC/data/P6-output-audio/\"\n",
        "    }\n",
        "\n",
        "\n",
        "    # Obtém o file_id do áudio de voz\n",
        "    file_id = message.voice.file_id\n",
        "\n",
        "    # Usa o file_id para obter informações sobre o arquivo\n",
        "    file_info = bot.get_file(file_id)\n",
        "\n",
        "    # Baixa o arquivo de áudio\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "\n",
        "    audio_entrada_file = f\"{locations['audio_entrada']}audio_entrada{agora_file()}.ogg\"\n",
        "\n",
        "    # Salva o áudio localmente (Google Drive)\n",
        "    with open(audio_entrada_file, 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "\n",
        "    print(f\"{agora_log()} Status 1: áudio de entrada recebido com sucesso! \\n»»» ({audio_entrada_file})\")\n",
        "\n",
        "    transcricao_entrada_file = f\"{locations['transcricao_entrada']}transcricao_entrada{agora_file()}.txt\"\n",
        "\n",
        "    audio_para_texto(audio_entrada_file, transcricao_entrada_file)\n",
        "\n",
        "    # Abre o arquivo 'arquivo.txt' em modo de leitura\n",
        "    with open(transcricao_entrada_file, 'r', encoding='utf-8') as arquivo:\n",
        "        # Lê todo o conteúdo do arquivo e armazena na variável 'conteudo'\n",
        "        conteudo = arquivo.read()\n",
        "\n",
        "    print(f\"{agora_log()} Status 2: transcrição da entrada gerada com sucesso! \\n»»» ({transcricao_entrada_file})\")\n",
        "\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "    ### STATUS 3:\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Captura a resposta gerada\n",
        "    generated_text = gerar_resposta(conteudo)\n",
        "\n",
        "    llm_response_file = f\"{locations['llm_response']}llm_response{agora_file()}.txt\"\n",
        "\n",
        "    # Salva o texto transcrito em um arquivo\n",
        "    with open(llm_response_file, \"w\") as f:\n",
        "      f.write(generated_text)\n",
        "\n",
        "    print(f\"{agora_log()} Status 3: resposta do LLM gerada com sucesso! \\n»»» ({llm_response_file})\")\n",
        "\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "    ### STATUS 4:\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    dados_api = {}\n",
        "    if generated_text is None:\n",
        "      dados_api = {\n",
        "                \"count\": 0,\n",
        "                \"page\": 1,\n",
        "                \"totalPages\": 1,\n",
        "                \"nextPage\": 0,\n",
        "                \"previousPage\": 0,\n",
        "                \"showingFrom\": 0,\n",
        "                \"showingTo\": 0,\n",
        "                \"items\": []\n",
        "              }\n",
        "    else:\n",
        "      lista_solicitacao = generated_text.split(\",\")\n",
        "      lista_solicitacao = [item.strip() for item in lista_solicitacao]\n",
        "      solicitacao = \" \".join(lista_solicitacao)\n",
        "      dados_api = realizar_consulta(solicitacao)\n",
        "\n",
        "    api_response_file = f\"{locations['api_response']}api_response{agora_file()}.json\"\n",
        "\n",
        "    # Salva o dicionário em um arquivo JSON\n",
        "    with open(api_response_file, \"w\") as f:\n",
        "      json.dump(dados_api, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"{agora_log()} Status 4: resposta do API IBGE obtida com sucesso! \\n»»» ({api_response_file})\")\n",
        "\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "    ### STATUS 5:\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    noticias = obter_noticias(dados_api)\n",
        "    noticia = noticias[0].to_dict()\n",
        "\n",
        "    for n in noticias:\n",
        "      lista_textos = [n.titulo, n.introducao]\n",
        "      if (encontrar_substring_em_listas(lista_solicitacao, lista_textos)):\n",
        "        noticia = n.to_dict()\n",
        "        break\n",
        "\n",
        "    noticia_file = f\"{locations['noticia']}noticia{agora_file()}.json\"\n",
        "\n",
        "    # Salva o dicionário em um arquivo JSON\n",
        "    with open(noticia_file, \"w\") as f:\n",
        "      json.dump(noticia, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"{agora_log()} Status 5: notícia salva com sucesso! \\n»»» ({noticia_file})\")\n",
        "\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "    ### STATUS 6:\n",
        "    ###------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    audio_saida_file = f\"{locations['audio_saida']}audio_saida{agora_file()}.ogg\"\n",
        "\n",
        "    texto_para_audio_json(noticia_file, audio_saida_file)\n",
        "\n",
        "    print(f\"{agora_log()} Status 6: áudio de saida gerado com sucesso! \\n»»» ({audio_saida_file})\")\n",
        "\n",
        "    # Caminho para o arquivo de voz no diretório raiz\n",
        "    voice = open(audio_saida_file, 'rb')\n",
        "\n",
        "    # Enviar a mensagem de voz para o usuário\n",
        "    bot.send_voice(message.chat.id, voice)\n",
        "\n",
        "    reply = f\"Data Publicação ({noticia.get('data_publicacao')})\\nLink: {noticia.get('link')}\"\n",
        "\n",
        "    # Responde ao usuário\n",
        "    bot.reply_to(message, reply)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UuJ_RsYAEE4"
      },
      "source": [
        "# **[2] – TESTES:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1tmHLX0edJd"
      },
      "source": [
        "## [2.1] – GOOGLE DRIVE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpVISiNddmFJ"
      },
      "source": [
        "### [2.1.1] – *GOOGLE DRIVE » TESTE DE FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "yUf9W5TrdrdP",
        "outputId": "94dc7eec-153b-4d2e-863c-fed77a45a375"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'obter_chave' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f3c32e7bd6ed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobter_chave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'telegram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobter_chave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'googlecloud'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'obter_chave' is not defined"
          ]
        }
      ],
      "source": [
        "print(obter_chave(chaves, 'telegram'))\n",
        "print(obter_chave(chaves, 'googlecloud'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRg4PtO8orNZ"
      },
      "source": [
        "## [2.2] – OPENAI WHISPER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDb0AGbo_ML"
      },
      "source": [
        "### [2.2.1] – *OPENAI WHISPER » TESTE DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "aJryuoYvpfav",
        "outputId": "1079ea9f-cdb5-4a8a-c8a8-c4dbc86bf001"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'audio_para_texto' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e186d9226392>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marquivo_entrada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/IHC/data/P1-input-audio/voice.ogg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0marquivo_saida\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/IHC/data/P2-input-txt/transcricao2.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maudio_para_texto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo_entrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marquivo_saida\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_para_texto' is not defined"
          ]
        }
      ],
      "source": [
        "arquivo_entrada = \"/content/drive/MyDrive/IHC/data/P1-input-audio/voice.ogg\"\n",
        "arquivo_saida = \"/content/drive/MyDrive/IHC/data/P2-input-txt/transcricao2.txt\"\n",
        "audio_para_texto(arquivo_entrada, arquivo_saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTmUoaCpHRoZ"
      },
      "source": [
        "## [2.3] – GOOGLE CLOUD:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_o9bVSH1tE"
      },
      "source": [
        "### [2.3.1] – *GOOGLE CLOUD » TESTE DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "CzgtlFBMJsNa",
        "outputId": "a75da4a0-561e-44b7-ac55-b56f691eebab"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'gerar_arquivo_de_audio' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9af9ee309ffe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marquivo_entrada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/IHC/data/P4-output-txt/perguntas_respostas.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlocal_arquivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/IHC/data/P5-output-audio/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgerar_arquivo_de_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo_entrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_arquivo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gerar_arquivo_de_audio' is not defined"
          ]
        }
      ],
      "source": [
        "arquivo_entrada = \"/content/drive/MyDrive/IHC/data/P4-output-txt/perguntas_respostas.txt\"\n",
        "local_arquivo = \"/content/drive/MyDrive/IHC/data/P5-output-audio/\"\n",
        "gerar_arquivo_de_audio(arquivo_entrada, local_arquivo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY0ZtqlGMy-V"
      },
      "source": [
        "## [2.4] – LARGE LANGUAGE MODEL (LLM):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVZoorgnNFd7"
      },
      "source": [
        "### [2.4.1] – *LARGE LANGUAGE MODEL (LLM) » TESTE DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2L4nd8oNL8v"
      },
      "outputs": [],
      "source": [
        "# Gera o texto a partir da entrada\n",
        "response = pipeline(\"Hey how are you doing today?\")\n",
        "\n",
        "# Captura a resposta gerada\n",
        "generated_text = response[0][\"generated_text\"]\n",
        "\n",
        "# Exibe a resposta\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9U0ZNfkUgN"
      },
      "source": [
        "## [2.5] – API IBGE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-QUtZIkcWB"
      },
      "source": [
        "### [2.5.1] – *API IBGE » TESTE DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3jQgrCsktWl"
      },
      "outputs": [],
      "source": [
        "solicitacao = input('> ')\n",
        "resultado = realizar_consulta(solicitacao)\n",
        "if resultado is None:\n",
        "    print(\"Desculpe, nenhuma informação encontrada sobre o assunto!\")\n",
        "else:\n",
        "    print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L9ZIR6ZPYiQ"
      },
      "source": [
        "# **[3] – EXECUÇÃO:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwla8di4hRBX"
      },
      "source": [
        "Este trecho de código inicia a execução do bot do Telegram, permitindo que ele comece a monitorar e responder a mensagens recebidas em tempo real. O método bot.polling() mantém o bot em funcionamento contínuo, aguardando novas interações com os usuários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "swxo4qm3PqO4"
      },
      "outputs": [],
      "source": [
        "bot.polling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZyRR74C_W07"
      },
      "source": [
        "# **[4] – FORA DE USO:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFo1nWh4Pvl5"
      },
      "source": [
        "## [1.3] – GOOGLE CLOUD TEXT-TO-SPEECH:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLulJRZpZVH7"
      },
      "source": [
        "### [1.3.1] – *GOOGLE CLOUD TEXT-TO-SPEECH » INSTALAÇÃO DAS DEPENDÊNCIAS:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQUZLe6Ef48D"
      },
      "source": [
        "Instala as bibliotecas necessárias para a utilização do Google Cloud Text-to-Speech (google-cloud-texttospeech), manipulação de áudio (pydub), e a ferramenta ffmpeg para converter e processar arquivos de áudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-qLu3ODQ6xO"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-texttospeech\n",
        "!pip install pydub\n",
        "!sudo apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouBb9VpZ2rP"
      },
      "source": [
        "### [1.3.2] – *GOOGLE CLOUD TEXT-TO-SPEECH » IMPLEMENTAÇÃO DA FUNÇÃO:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzNXbS94gCjY"
      },
      "source": [
        "Converte texto em áudio usando o Google Cloud Text-to-Speech. Primeiro, define as credenciais de acesso e cria uma função que gera um arquivo de áudio a partir de um texto e uma voz especificados. Outra função lê um arquivo JSON contendo um título e uma introdução, gera áudios separados para cada um com vozes diferentes, e os combina em um único arquivo .ogg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z-ek_TV3P64I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.cloud import texttospeech\n",
        "from google.cloud.texttospeech import SsmlVoiceGender\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def gerar_audio_google_cloud(text, voice, output_file):\n",
        "\n",
        "    client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "    # Configura a entrada como SSML\n",
        "    synthesis_input = texttospeech.SynthesisInput(ssml=text)\n",
        "\n",
        "\n",
        "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "    response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "    with open(output_file, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "# arquivo_entrada, arquivo_saida\n",
        "def texto_para_audio_json(input_file, output_file):\n",
        "\n",
        "  with open(input_file, 'r') as arquivo:\n",
        "      noticia = json.load(arquivo)\n",
        "\n",
        "  texto_titulo = noticia.get('titulo')\n",
        "  ssml_titulo = f\"\"\"\n",
        "                <speak>\n",
        "                    <p>{texto_titulo}</p>\n",
        "                </speak>\n",
        "                \"\"\"\n",
        "\n",
        "  texto_introducao = noticia.get('introducao')\n",
        "  ssml_introducao = f\"\"\"\n",
        "                    <speak>\n",
        "                        <p>{texto_introducao}</p>\n",
        "                        <break time=\"1s\"/>\n",
        "                        <p>Saiba mais no link abaixo.</p>\n",
        "                    </speak>\n",
        "                    \"\"\"\n",
        "\n",
        "  # Escolha o gênero da voz: SsmlVoiceGender.MALE\n",
        "  voz_homem = texttospeech.VoiceSelectionParams(\n",
        "      language_code=\"pt-BR\",\n",
        "      name =\"pt-BR-Standard-B\",\n",
        "      ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
        "  )\n",
        "\n",
        "  # Escolha o gênero da voz: SsmlVoiceGender.FEMALE\n",
        "  voz_mulher = texttospeech.VoiceSelectionParams(\n",
        "      language_code=\"pt-BR\",\n",
        "      name =\"pt-BR-Standard-C\",\n",
        "      ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
        "  )\n",
        "\n",
        "  # Encontra a posição do penúltimo '_'\n",
        "  index = output_file.rfind('_', 0, output_file.rfind('_'))\n",
        "\n",
        "  # Divide a string com base na posição do penúltimo '_'\n",
        "  base = output_file[:index]\n",
        "  suffix = output_file[index + 1:-4]\n",
        "\n",
        "  # Monta as novas strings com as partes desejadas\n",
        "  titulo_file = f\"{base}_titulo_{suffix}.mp3\"\n",
        "  introducao_file = f\"{base}_introducao_{suffix}.mp3\"\n",
        "\n",
        "  gerar_audio_google_cloud(ssml_titulo, voz_homem, titulo_file)\n",
        "  gerar_audio_google_cloud(ssml_introducao, voz_mulher, introducao_file)\n",
        "\n",
        "  audios = []\n",
        "  audios.append(AudioSegment.from_mp3(titulo_file))\n",
        "  audios.append(AudioSegment.from_mp3(introducao_file))\n",
        "\n",
        "  audio = sum(audios)\n",
        "  audio.export(output_file, format='ogg')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uAohjQahNX-o",
        "zQleyvjJNz5s",
        "K0PQlixAebu1",
        "v_05IcrG81yG",
        "m4CMmZefXPx1",
        "zMNUK6zIf6oU",
        "Ca4xGTe0gOKQ",
        "XlJrsR89_jb6",
        "R-qdgtGS7-FC",
        "pGYPhykG8tEk",
        "9UuJ_RsYAEE4",
        "R1tmHLX0edJd",
        "TRg4PtO8orNZ",
        "cUDb0AGbo_ML",
        "qTmUoaCpHRoZ",
        "WR_o9bVSH1tE",
        "ZFo1nWh4Pvl5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}